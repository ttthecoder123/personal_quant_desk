{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üìä Market Data Exploration Guide\n",
    "\n",
    "This notebook shows you how to load and explore parquet data from your Personal Quant Desk.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Load parquet files\n",
    "- Explore OHLCV data\n",
    "- Visualize price action\n",
    "- Calculate basic statistics\n",
    "- Check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting setup\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Finding Your Data\n",
    "\n",
    "First, let's see what parquet files you have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "find-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_dir = Path('../data/processed')\n",
    "\n",
    "# List all parquet files\n",
    "if data_dir.exists():\n",
    "    parquet_files = list(data_dir.glob('*.parquet'))\n",
    "    \n",
    "    if parquet_files:\n",
    "        print(f\"üìÅ Found {len(parquet_files)} parquet files:\\n\")\n",
    "        for f in parquet_files:\n",
    "            size_mb = f.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  ‚Ä¢ {f.name:30s} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No parquet files found!\")\n",
    "        print(\"\\nüí° First download some data:\")\n",
    "        print(\"   cd ../data\")\n",
    "        print(\"   python main.py update --symbols SPY --days 100\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Directory not found: {data_dir}\")\n",
    "    print(\"\\nüí° Create it with: mkdir -p ../data/processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Loading a Parquet File\n",
    "\n",
    "Let's load one file and explore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a file (change this to your actual file)\n",
    "symbol = 'SPY'  # Change to your symbol\n",
    "file_path = data_dir / f'{symbol}.parquet'\n",
    "\n",
    "# Load the parquet file\n",
    "if file_path.exists():\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {symbol} data\")\n",
    "    print(f\"\\nüìä Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üìÖ Date range: {df.index.min().date()} to {df.index.max().date()}\")\n",
    "    print(f\"\\nüîç Columns: {', '.join(df.columns.tolist())}\")\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {file_path}\")\n",
    "    print(\"\\nüí° Available files:\")\n",
    "    if parquet_files:\n",
    "        print(f\"   Try: symbol = '{parquet_files[0].stem}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first few rows\n",
    "print(\"üìà First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview-tail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview last few rows\n",
    "print(\"üìâ Last 5 rows:\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"üìã Data Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"‚ö†Ô∏è  Missing values found:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"‚úÖ No missing values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"üìä Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Price Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot closing price\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(df.index, df['Close'], linewidth=1.5, label='Close Price')\n",
    "ax.fill_between(df.index, df['Low'], df['High'], alpha=0.2, label='High-Low Range')\n",
    "\n",
    "ax.set_title(f'{symbol} Price History', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Price ($)', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-ohlc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot OHLC candlestick-style\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Price\n",
    "ax1.plot(df.index, df['Close'], linewidth=2, label='Close', color='#2E86DE')\n",
    "ax1.plot(df.index, df['Open'], linewidth=1, alpha=0.7, label='Open', color='#54A0FF')\n",
    "ax1.fill_between(df.index, df['Low'], df['High'], alpha=0.15, color='#2E86DE')\n",
    "ax1.set_ylabel('Price ($)', fontsize=12)\n",
    "ax1.set_title(f'{symbol} OHLC Data', fontsize=16, fontweight='bold')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Volume\n",
    "ax2.bar(df.index, df['Volume'], width=0.8, alpha=0.6, color='#EE5A6F')\n",
    "ax2.set_ylabel('Volume', fontsize=12)\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Calculate Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "df['Returns'] = df['Close'].pct_change()\n",
    "\n",
    "print(\"üìà Returns Statistics:\")\n",
    "print(f\"  Mean return: {df['Returns'].mean():.4%}\")\n",
    "print(f\"  Std dev:     {df['Returns'].std():.4%}\")\n",
    "print(f\"  Min return:  {df['Returns'].min():.4%}\")\n",
    "print(f\"  Max return:  {df['Returns'].max():.4%}\")\n",
    "print(f\"  Sharpe (annualized): {(df['Returns'].mean() / df['Returns'].std() * np.sqrt(252)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-returns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot returns distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Returns over time\n",
    "ax1.plot(df.index, df['Returns'], linewidth=0.8, alpha=0.7)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.set_title('Daily Returns Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Return')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Returns histogram\n",
    "ax2.hist(df['Returns'].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=df['Returns'].mean(), color='red', linestyle='--', label=f\"Mean: {df['Returns'].mean():.4%}\")\n",
    "ax2.set_title('Returns Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Return')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Simple Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indicators",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate moving averages\n",
    "df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "df['SMA_200'] = df['Close'].rolling(window=200).mean()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "df['BB_middle'] = df['Close'].rolling(window=20).mean()\n",
    "df['BB_std'] = df['Close'].rolling(window=20).std()\n",
    "df['BB_upper'] = df['BB_middle'] + (df['BB_std'] * 2)\n",
    "df['BB_lower'] = df['BB_middle'] - (df['BB_std'] * 2)\n",
    "\n",
    "print(\"‚úÖ Calculated moving averages and Bollinger Bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-indicators",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with indicators\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Price and moving averages\n",
    "ax.plot(df.index, df['Close'], linewidth=2, label='Close', color='black')\n",
    "ax.plot(df.index, df['SMA_20'], linewidth=1.5, label='SMA 20', color='blue', alpha=0.7)\n",
    "ax.plot(df.index, df['SMA_50'], linewidth=1.5, label='SMA 50', color='orange', alpha=0.7)\n",
    "ax.plot(df.index, df['SMA_200'], linewidth=1.5, label='SMA 200', color='red', alpha=0.7)\n",
    "\n",
    "# Bollinger Bands\n",
    "ax.fill_between(df.index, df['BB_upper'], df['BB_lower'], alpha=0.1, color='gray', label='Bollinger Bands')\n",
    "\n",
    "ax.set_title(f'{symbol} Price with Technical Indicators', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Price ($)', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Load Multiple Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple symbols\n",
    "symbols = ['SPY', 'QQQ', 'GLD']  # Change to your symbols\n",
    "data_dict = {}\n",
    "\n",
    "for symbol in symbols:\n",
    "    file_path = data_dir / f'{symbol}.parquet'\n",
    "    if file_path.exists():\n",
    "        data_dict[symbol] = pd.read_parquet(file_path)\n",
    "        print(f\"‚úÖ Loaded {symbol}: {len(data_dict[symbol])} rows\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {symbol}.parquet not found\")\n",
    "\n",
    "if data_dict:\n",
    "    # Create combined dataframe with closing prices\n",
    "    closes = pd.DataFrame({symbol: df['Close'] for symbol, df in data_dict.items()})\n",
    "    print(f\"\\nüìä Combined data shape: {closes.shape}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No data loaded. Download some data first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and plot multiple symbols\n",
    "if data_dict:\n",
    "    # Normalize to 100 at start\n",
    "    normalized = (closes / closes.iloc[0]) * 100\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    for col in normalized.columns:\n",
    "        ax.plot(normalized.index, normalized[col], linewidth=2, label=col)\n",
    "    \n",
    "    ax.set_title('Normalized Price Comparison (Base = 100)', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Normalized Price', fontsize=12)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dict and len(data_dict) > 1:\n",
    "    # Calculate returns\n",
    "    returns = closes.pct_change().dropna()\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr = returns.corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(corr, annot=True, fmt='.3f', cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    ax.set_title('Returns Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Correlation Matrix:\")\n",
    "    print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "Now that you know how to load and explore data, you can:\n",
    "\n",
    "1. **Use the data ingestion system**:\n",
    "   ```python\n",
    "   from data.ingestion import HybridDataManager\n",
    "   manager = HybridDataManager()\n",
    "   data, metadata = manager.download_instrument('AAPL', '2024-01-01', '2024-12-31')\n",
    "   ```\n",
    "\n",
    "2. **Use the feature engineering pipeline**:\n",
    "   ```python\n",
    "   from data.features.feature_pipeline import FeaturePipeline\n",
    "   pipeline = FeaturePipeline()\n",
    "   features = pipeline.generate_features(df, 'SPY')\n",
    "   ```\n",
    "\n",
    "3. **Explore backtesting**:\n",
    "   - Check out the backtesting module\n",
    "   - Test strategies on historical data\n",
    "\n",
    "4. **Build custom strategies**:\n",
    "   - Use the strategies module\n",
    "   - Create your own trading logic\n",
    "\n",
    "Happy exploring! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Personal Quant Desk - AI-Assisted Trading System

A comprehensive, semi-automated trading system for commodities, indices, and FX pairs with AI-driven signal generation and enhanced data ingestion capabilities.

## ðŸš€ Project Status

- âœ… **Step 1: Project Structure** - COMPLETE
- âœ… **Step 2: Data Ingestion** - COMPLETE (with Alpha Vantage enhancement)
- âœ… **Step 3: Feature Engineering** - COMPLETE
- â³ **Step 4: Signal Generation** - NEXT
- â³ **Step 5: Strategy Development** - Pending
- â³ **Step 7: Risk Management** - Pending
- â³ **Step 10: Backtesting** - Pending
- â³ **Step 12: Execution** - Pending
- â³ **Step 13: Monitoring** - Pending

## ðŸ“Š Data Sources & Features

### Primary Data Sources
- **Alpha Vantage**: Recent 100 days (high quality, rate limited: 5 calls/min, 25/day)
- **Yahoo Finance**: Historical data (reliable, unlimited)
- **Hybrid Strategy**: Automatic source selection based on date range and asset class

### Enhanced Features
- ðŸ”„ **Intelligent Source Selection**: Alpha Vantage for recent data quality, yfinance for historical
- ðŸ“ˆ **Corporate Action Detection**: Automatic detection of splits and dividends
- ðŸŽ¯ **Quality Scoring**: Composite quality metrics (0-100) with production thresholds
- ðŸ’¾ **Smart Caching**: SQLite-based API response caching to minimize rate limits
- ðŸ” **Symbol Mapping**: Support for commodities (CL=Fâ†’WTI) and FX pairs (AUDUSD=Xâ†’AUD/USD)
- âš¡ **Rate Limiting**: Compliant with free API tiers

### Supported Instruments
- **Commodities**: WTI Oil (CL=F), Gold (GC=F), Copper (HG=F)
- **Indices**: SPY, QQQ, ASX (^AXJO)
- **FX Pairs**: AUDUSD, USDJPY, EURUSD

## ðŸ“ Project Structure

```
personal_quant_desk/              # Single consolidated root
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml              # System configuration
â”‚   â””â”€â”€ data_sources.yaml        # Alpha Vantage & data source config
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ingestion/               # Enhanced data ingestion system
â”‚   â”‚   â”œâ”€â”€ alpha_vantage.py    # Alpha Vantage adapter with caching
â”‚   â”‚   â”œâ”€â”€ downloader.py       # HybridDataManager for intelligent sourcing
â”‚   â”‚   â”œâ”€â”€ validator.py        # Corporate action detection & validation
â”‚   â”‚   â”œâ”€â”€ quality_scorer.py   # Composite quality scoring
â”‚   â”‚   â”œâ”€â”€ storage.py          # Parquet storage with compression
â”‚   â”‚   â”œâ”€â”€ catalog.py          # Data catalog with quality tracking
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ features/                # Feature engineering (Step 3)
â”‚   â”‚   â”œâ”€â”€ base_features.py    # Price/volume transformations
â”‚   â”‚   â”œâ”€â”€ technical_features.py  # Technical indicators (RSI, MACD, etc.)
â”‚   â”‚   â”œâ”€â”€ microstructure.py   # Market microstructure features
â”‚   â”‚   â”œâ”€â”€ regime_features.py  # Regime detection
â”‚   â”‚   â”œâ”€â”€ cross_asset.py      # Cross-asset correlations
â”‚   â”‚   â”œâ”€â”€ commodity_specific.py  # Commodity features
â”‚   â”‚   â”œâ”€â”€ feature_pipeline.py # Feature generation orchestration
â”‚   â”‚   â”œâ”€â”€ feature_store.py    # Feature storage & versioning
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ feature_config.yaml  # Feature configuration
â”‚   â”‚   â”œâ”€â”€ computed/           # Generated features (Parquet)
â”‚   â”‚   â””â”€â”€ reports/            # Feature quality reports
â”‚   â”œâ”€â”€ processed/               # Parquet files
â”‚   â”œâ”€â”€ cache/                   # API response cache (SQLite)
â”‚   â”œâ”€â”€ catalog/                 # Metadata storage
â”‚   â”œâ”€â”€ quality_reports/         # Quality assessment reports
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ instruments.yaml    # Instrument definitions
â”‚   â”œâ”€â”€ logs/                   # Data pipeline logs
â”‚   â””â”€â”€ main.py                 # CLI with hybrid mode options
â”œâ”€â”€ models/                      # ML models (Step 4)
â”œâ”€â”€ strategies/                  # Trading strategies (Step 5)
â”œâ”€â”€ risk/                        # Risk management (Step 7)
â”œâ”€â”€ execution/                   # Order execution (Step 12)
â”œâ”€â”€ backtesting/                 # Strategy backtesting (Step 10)
â”œâ”€â”€ monitoring/                  # System monitoring (Step 13)
â”œâ”€â”€ notebooks/                   # Jupyter analysis notebooks
â”œâ”€â”€ tests/                       # Comprehensive test suite
â”œâ”€â”€ utils/                       # Shared utilities
â”œâ”€â”€ logs/                        # System-wide logs
â”œâ”€â”€ requirements.txt             # All dependencies
â”œâ”€â”€ .env.template               # Environment variables template
â”œâ”€â”€ .gitignore                  # Git ignore patterns
â””â”€â”€ README.md                   # This file
```

## ðŸ”§ Quick Start

### 1. Environment Setup
```bash
# Quick navigation (works from any directory!)
quant desk

# Or navigate manually
cd personal_quant_desk

# Copy environment template (includes working Alpha Vantage API key)
cp .env.template .env

# The .env file now contains a working Alpha Vantage API key
# You can use it as-is or replace with your own key if you have one
```

> ðŸ’¡ **New!** You can now type `quant desk` from any terminal to jump to your project! See [TERMINAL_SHORTCUTS.md](TERMINAL_SHORTCUTS.md) for all commands.

### 2. Test API Key (Optional)
```bash
# Verify Alpha Vantage API key works (no dependencies needed)
python test_api_key.py
```

### 3. Install Dependencies
```bash
# Install core requirements
pip install -r requirements.txt

# For development (optional)
pip install -e .
```

### 4. Data Ingestion

#### Download Historical Data (5 years)
```bash
cd data
python main.py historical --years 5
```

#### Daily Updates with Hybrid Mode
```bash
cd data
python main.py update --days 5
```

#### Specific Instruments
```bash
cd data
python main.py update --symbols "SPY,AUDUSD=X,CL=F" --days 10
```

#### Disable Hybrid Mode (yfinance only)
```bash
cd data
python main.py historical --years 2 --no-hybrid
```

### 5. Quality Reports
```bash
cd data
python main.py report
```

### 6. Pipeline Statistics
```bash
cd data
python main.py stats
```

## ðŸ“Š Data Quality Features

### Quality Scoring (0-100)
- **Completeness** (30%): Non-missing data percentage
- **Consistency** (30%): OHLC relationships and logical checks
- **Timeliness** (20%): Data freshness and update frequency
- **Accuracy** (20%): Statistical accuracy and outlier analysis

### Quality Thresholds
- **Production Ready**: â‰¥85 (Excellent/Good quality)
- **Review Required**: 70-84 (Fair quality)
- **Reject**: <70 (Poor quality)

### Corporate Actions
- **Split Detection**: >50% overnight price changes
- **Dividend Detection**: <10% price adjustments on ex-dates
- **Confidence Scoring**: 0.0-1.0 based on price patterns and volume

## ðŸŽ¯ Feature Engineering (Step 3 - COMPLETE)

### Feature Categories
The system generates **150+ features per symbol** across multiple categories:

#### Base Features
- **Returns**: Multiple horizons (1, 5, 20, 60, 120 periods)
- **Volume**: Transformations and rolling statistics (5, 20, 60 periods)
- **Volatility**: Multiple window sizes (5, 20, 60 periods)

#### Technical Indicators
- **Momentum**: RSI (14, 30), MACD, Stochastic, ADX
- **Trend**: Moving average crosses (10/20, 20/50, 50/200)
- **Directional**: Plus/Minus DI, trend strength

#### Market Microstructure
- **Kyle's Lambda**: Price impact (20, 60 window)
- **Spread Analysis**: Bid-ask spread estimation
- **Order Flow**: Volume-based microstructure metrics

#### Regime Detection
- **Volatility Regimes**: 252-day lookback
- **Trend States**: Multiple periods (20, 60, 120)
- **CUSUM**: Change point detection (60 window)

#### Cross-Asset Features
- **Correlations**: Rolling windows (20, 60, 120)
- **Pairs**: Gold-Copper, Oil-Gold, SPY-QQQ, AUD-Gold

#### Commodity-Specific
- **Seasonality**: Time-based patterns
- **Curve Analysis**: Commodity-specific features

### Feature Pipeline Commands

```bash
cd data

# Generate features for all symbols
python main.py features --symbols "SPY,CL=F,GC=F"

# Generate with custom configuration
python main.py features --config features/config/feature_config.yaml

# View feature statistics
python main.py feature-stats
```

### Feature Storage
- **Format**: Parquet with Snappy compression
- **Versioning**: Automatic version control
- **Location**: `data/features/computed/`
- **Reports**: Quality metrics in `data/features/reports/`

## ðŸ”Œ API Configuration

### Alpha Vantage (Free Tier)
- **API Key**: Pre-configured in `.env.template` (Z0WR10WWKFEH25JO)
- **Rate Limits**: 5 calls/minute, 25 calls/day
- **Best For**: Recent forex data (last 100 days)
- **Caching**: 24-hour SQLite cache to minimize API usage
- **Ready to Use**: No additional setup required

### Yahoo Finance
- **Rate Limits**: None (respectful usage)
- **Best For**: Historical data, indices, commodities
- **Reliability**: High for data older than 100 days

## ðŸ› ï¸ Development

### Code Quality
```bash
# Code formatting
black .

# Linting
flake8 .

# Type checking
mypy .

# Tests
pytest
```

### Adding New Data Sources
1. Create adapter in `data/ingestion/`
2. Add configuration to `data/config/data_sources.yaml`
3. Update `HybridDataManager` selection logic
4. Add tests in `tests/`

## ðŸ“ˆ Usage Examples

### Basic Data Download
```python
from data.ingestion import HybridDataManager

# Initialize hybrid manager
manager = HybridDataManager()

# Download with intelligent source selection
data, metadata = manager.download_instrument('SPY', '2023-01-01', '2024-01-01')

print(f"Downloaded {len(data)} rows")
print(f"Sources used: {metadata['sources_used']}")
print(f"Quality score: {metadata['quality_score']}")
```

### Quality Assessment
```python
from data.ingestion import DataValidator, QualityScorer

# Validate data
validator = DataValidator()
cleaned_data, quality_metrics = validator.validate_ohlcv(data, 'SPY')

# Score quality
scorer = QualityScorer()
quality_result = scorer.calculate_composite_score(cleaned_data, 'SPY')

print(f"Overall quality: {quality_result.overall_score}")
print(f"Corporate actions detected: {len(quality_metrics.corporate_actions)}")
```

## ðŸš¨ Monitoring & Alerts

### Quality Monitoring
- **Degradation Alerts**: Quality drops >10 points
- **Minimum Threshold**: Alert if quality <60
- **Trend Tracking**: Historical quality score trends

### API Usage Monitoring
- **Rate Limit Tracking**: Daily quota usage (Alpha Vantage)
- **Performance Monitoring**: Download times and success rates
- **Cache Hit Rates**: API cache effectiveness

## ðŸ”„ Data Pipeline Flow

1. **Source Selection**: HybridDataManager chooses optimal data source
2. **Download**: API calls with rate limiting and caching
3. **Validation**: OHLC consistency, missing value handling
4. **Corporate Actions**: Split/dividend detection and flagging
5. **Quality Scoring**: Composite quality assessment
6. **Storage**: Parquet format with Snappy compression
7. **Cataloging**: Metadata storage with lineage tracking

## ðŸ›¡ï¸ Error Handling

- **API Failures**: Automatic fallback between sources
- **Rate Limiting**: Exponential backoff and queue management
- **Data Quality**: Configurable acceptance thresholds
- **Circuit Breaker**: Stop retrying after repeated failures

## ðŸ“ Logging

All operations are logged with structured logging:
- **Data Pipeline**: `data/logs/pipeline_YYYY-MM-DD.log`
- **System**: `logs/system.log`
- **API Calls**: Debug mode for API request/response logging

## ðŸ”® Next Steps

1. **Signal Generation** (Step 4): ML models for trade signals
2. **Strategy Development** (Step 5): Complete trading strategies
3. **Risk Management** (Step 7): Position sizing and risk controls
4. **Backtesting** (Step 10): Historical strategy performance
5. **Execution** (Step 12): Broker integration and order management
6. **Monitoring** (Step 13): Real-time system monitoring and alerts

## ðŸ¤ Contributing

1. Follow the existing code structure
2. Add tests for new features
3. Update documentation
4. Use type hints and docstrings
5. Run quality checks before submitting

## ðŸ“„ License

This project is for educational and personal use. Please respect API rate limits and terms of service.

---

**Note**: This is a sophisticated trading system. Always test thoroughly with paper trading before using real money. Past performance does not guarantee future results.
